{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7e3280-0ab8-4f57-99cb-04d90ce712bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea597f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5493e7c-04ae-499a-893c-d33f9705e1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Load Data\n",
    "df = pd.read_csv('Restaurant_Reviews.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "936e5d9c-7b2b-40fe-8664-825eb7fe20df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: Clean the text\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text).lower().split()\n",
    "    return text\n",
    "\n",
    "df['Cleaned'] = df['Review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b184c110-22a7-4831-b981-16e33cac38bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: Split data into train and test (80/20)\n",
    "data = list(zip(df['Cleaned'], df['Liked']))\n",
    "random.seed(42)\n",
    "random.shuffle(data)\n",
    "\n",
    "split_idx = int(0.8 * len(data))\n",
    "train_data = data[:split_idx]\n",
    "test_data = data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8662d818-6aee-442b-86d4-f2d08a538e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: Training - Count words and classes\n",
    "word_counts = {\n",
    "    0: defaultdict(int),  # Negative\n",
    "    1: defaultdict(int),  # Positive\n",
    "}\n",
    "class_counts = {0: 0, 1: 0}\n",
    "total_words = {0: 0, 1: 0}\n",
    "\n",
    "for words, label in train_data:\n",
    "    class_counts[label] += 1\n",
    "    for word in words:\n",
    "        word_counts[label][word] += 1\n",
    "        total_words[label] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f152a60-5611-429a-b658-8daeab83f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: Vocabulary\n",
    "vocab = set(word for label in word_counts for word in word_counts[label])\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98fa31c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Improved Naive Bayes prediction: returns label and probability\n",
    "def predict_naive_bayes_granular(words):\n",
    "    scores = {}\n",
    "    total_docs = sum(class_counts.values())\n",
    "    for label in [0, 1]:\n",
    "        log_prob = math.log(class_counts[label] / total_docs)\n",
    "        for word in words:\n",
    "            word_freq = word_counts[label][word] + 1  # Laplace smoothing\n",
    "            word_prob = word_freq / (total_words[label] + vocab_size)\n",
    "            log_prob += math.log(word_prob)\n",
    "        scores[label] = log_prob\n",
    "    # Softmax normalization for probability\n",
    "    max_log = max(scores.values())\n",
    "    exp0 = math.exp(scores[0] - max_log)\n",
    "    exp1 = math.exp(scores[1] - max_log)\n",
    "    prob_pos = exp1 / (exp0 + exp1)\n",
    "    label = 1 if scores[1] > scores[0] else 0\n",
    "    return label, prob_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4090dd50-f822-46f9-a16f-e6fca454c9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Prediction function using Naive Bayes\n",
    "def predict_naive_bayes(words):\n",
    "    scores = {}\n",
    "    total_docs = sum(class_counts.values())\n",
    "    for label in [0, 1]:\n",
    "        log_prob = math.log(class_counts[label] / total_docs)\n",
    "        for word in words:\n",
    "            word_freq = word_counts[label][word] + 1  # Laplace smoothing\n",
    "            word_prob = word_freq / (total_words[label] + vocab_size)\n",
    "            log_prob += math.log(word_prob)\n",
    "        scores[label] = log_prob\n",
    "    return 1 if scores[1] > scores[0] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c7c91e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n",
      "Confusion Matrix:\n",
      " [[78 22]\n",
      " [25 75]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.76      0.78      0.77       100\n",
      "    Positive       0.77      0.75      0.76       100\n",
      "\n",
      "    accuracy                           0.77       200\n",
      "   macro avg       0.77      0.77      0.76       200\n",
      "weighted avg       0.77      0.77      0.76       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation with granular sentiment, confusion matrix, and classification report\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "probs = []\n",
    "\n",
    "for words, true_label in test_data:\n",
    "    pred, prob_pos = predict_naive_bayes_granular(words)\n",
    "    true_labels.append(true_label)\n",
    "    pred_labels.append(pred)\n",
    "    probs.append(prob_pos)\n",
    "\n",
    "accuracy = np.mean(np.array(pred_labels) == np.array(true_labels))\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(true_labels, pred_labels, target_names=['Negative', 'Positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e59d3de5-b79a-43a5-8763-0068f8976055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "# STEP 7: Evaluate on test data\n",
    "correct = 0\n",
    "for words, true_label in test_data:\n",
    "    pred = predict_naive_bayes(words)\n",
    "    if pred == true_label:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / len(test_data)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed4c7bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters saved to model_params.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save model parameters for reuse\n",
    "import pickle\n",
    "\n",
    "with open('model_params.pkl', 'wb') as f:\n",
    "    pickle.dump((word_counts, class_counts, total_words, vocab_size), f)\n",
    "print(\"Model parameters saved to model_params.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f0cfee3-be0b-4893-92b7-22f3dfe50416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model parameters saved to model_params.pkl\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# bundle them into a tuple\n",
    "model_params = (word_counts, class_counts, total_words, vocab_size)\n",
    "\n",
    "# save to a file\n",
    "with open('model_params.pkl', 'wb') as f:\n",
    "    pickle.dump(model_params, f)\n",
    "\n",
    "print(\"✅ Model parameters saved to model_params.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176316a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb549cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters loaded from model_params.pkl\n"
     ]
    }
   ],
   "source": [
    "# Load model parameters from pickle\n",
    "import pickle\n",
    "\n",
    "with open('model_params.pkl', 'rb') as f:\n",
    "    word_counts, class_counts, total_words, vocab_size = pickle.load(f)\n",
    "print(\"Model parameters loaded from model_params.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f49c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d2982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c158a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
